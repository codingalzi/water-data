{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 영산강 보 통합 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**필수 라이브러리**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**matplotlib 한글 설정**\n",
    "\n",
    "- 운영체제에 따른 한글 지원 설정. 윈도우, 우분투, 구글 코랩 지원.\n",
    "- 참고: [matplotlib에서 한글 지원하기](https://github.com/codingalzi/datapy/blob/master/matplotlib-korean.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "\n",
    "if platform.system() == 'Windows': # 윈도우\n",
    "    from matplotlib import font_manager, rc\n",
    "    font_path = \"C:/Windows/Fonts/NGULIM.TTF\"\n",
    "    font = font_manager.FontProperties(fname=font_path).get_name()\n",
    "    rc('font', family=font)\n",
    "elif platform.system() == 'Linux': # 우분투 또는 구글 코랩\n",
    "    # please run the following commented out codes just once\n",
    "#     if 'google.colab' in str(get_ipython()):\n",
    "#         !apt-get install -y fonts-nanum*\n",
    "#     else:\n",
    "#         !sudo apt-get install -y fonts-nanum*\n",
    "#     !fc-cache -fv\n",
    "    \n",
    "    applyfont = \"NanumBarunGothic\"\n",
    "    import matplotlib.font_manager as fm\n",
    "    if not any(map(lambda ft: ft.name == applyfont, fm.fontManager.ttflist)):\n",
    "        fm.fontManager.addfont(\"/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf\")\n",
    "    plt.rc(\"font\", family=applyfont)\n",
    "    plt.rc(\"axes\", unicode_minus=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**데이터 저장소**\n",
    "\n",
    "데이터 원본 파일 저장소는 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://github.com/codingalzi/water-data/raw/master/reservoirs/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**영산강(엑셀) 자료를 데이터프레임으로 불러오기**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모든 지역의 데이터 불러오기: 평동천, 광산, 장성천2, 문평천, 영산포2, 함평, 무안2\n",
    "\n",
    "- `header=0`: 0번 행을 header로 지정, 즉 열 인덱스로 사용.\n",
    "- `sheet_name=None`: 모든 워크시트 가져오기. 워크시트별로 하나의 df 생성. 반환값은 사전.\n",
    "- `na_values=0`: 0으로 입력된 값도 결측치로 처리\n",
    "- `index_col=1`: 측정일을 행 인덱스로 사용\n",
    "- `parse_dates=True`: 행 인덱스로 사용되는 날짜 대상 파싱 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주의: 엑셀파일을 불러오기 위해 아래 모듈이 필요하다.\n",
    "\n",
    "# !pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "yeongsan = pd.read_excel(base_url+\"Yeongsan.xlsx\",\n",
    "                            header=0, \n",
    "                            sheet_name=None,\n",
    "                            na_values=0,\n",
    "                            index_col=1, \n",
    "                            parse_dates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "포함된 보(reservoir)의 지역명은 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['1_평동천', '2_광산', '3_장성천2', '4_문평천', '5_영산포2', '6_함평', '7_무안2'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations = yeongsan.keys()\n",
    "locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**데이터 합치기**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지역별 데이터셋 크기는 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_평동천: \t(440, 19)\n",
      "2_광산: \t(510, 19)\n",
      "3_장성천2: \t(435, 19)\n",
      "4_문평천: \t(435, 19)\n",
      "5_영산포2: \t(456, 19)\n",
      "6_함평: \t(456, 19)\n",
      "7_무안2: \t(534, 19)\n",
      "총 데이터수: 3266\n"
     ]
    }
   ],
   "source": [
    "total_data = 0\n",
    "\n",
    "for loc in locations:\n",
    "    ys_loc = yeongsan[loc]\n",
    "    total_data += ys_loc.shape[0]\n",
    "    print(f\"{loc}: \\t{ys_loc.shape}\")\n",
    "    \n",
    "print(\"총 데이터수:\", total_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모든 지역의 데이터를 단순히 합쳐서\n",
    "총 3266개의 데이터 샘플을 갖는 데이터셋으로 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3266, 19)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yongsan_total = pd.concat([yeongsan[loc] for loc in locations])\n",
    "yongsan_total.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "동일 날짜를 제외하면 1310개의 데이터에 불과하다.\n",
    "하지만 장소가 다르기에 중복 날짜를 모두 인정한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1310,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 중복 날짜 수\n",
    "\n",
    "yongsan_total.index.unique().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**주요 특성**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "수온, BOD, COD, TN, TP, 유량 등 6개의 주요 특성만을 이용하여 클로로필-A 예측하려 한다.\n",
    "원 데이터셋에 포함된 19개의 특성은 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['측정소명',\n",
       " '회차',\n",
       " '수온(℃)',\n",
       " 'DO(㎎/L)',\n",
       " 'BOD(㎎/L)',\n",
       " 'COD(㎎/L)',\n",
       " '클로로필 a(㎎/㎥)',\n",
       " 'TN(㎎/L)',\n",
       " 'TP(㎎/L)',\n",
       " 'TOC(㎎/L)',\n",
       " '수소이온농도',\n",
       " '전기전도도(μS/㎝)',\n",
       " '용존총질소(㎎/L)',\n",
       " '암모니아성 질소(㎎/L)',\n",
       " '질산성 질소(㎎/L)',\n",
       " '용존총인(㎎/L)',\n",
       " '인산염인(㎎/L)',\n",
       " 'SS(㎎/L)',\n",
       " '유량(㎥/s)']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(yongsan_total.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "주요 특성 6개와 타깃으로 사용될 특성인 클로로필-A를 별도로 지정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_important = ['수온(℃)', 'BOD(㎎/L)', 'COD(㎎/L)', 'TN(㎎/L)', 'TP(㎎/L)', '유량(㎥/s)', '클로로필 a(㎎/㎥)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 입력데이터셋 특성 6개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "six_features = features_important[:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 타깃 특성: 클로로필-A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_feature = features_important[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**타깃 결측치 제거**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "타깃으로 사용될 클로로필-A 특성에 48개의 결측치가 존재한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yongsan_total[target_feature].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "타깃에 결측치가 포함되면 안되기에 해당 데이터 샘플들을 제거한 후에\n",
    "총 3218개의 데이터만 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3218, 19)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = yongsan_total[target_feature].isna()\n",
    "yongsan = yongsan_total[~mask]\n",
    "\n",
    "yongsan.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**핵심 특성만 사용**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제부터 언급된 7개의 특성만 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>수온(℃)</th>\n",
       "      <th>BOD(㎎/L)</th>\n",
       "      <th>COD(㎎/L)</th>\n",
       "      <th>TN(㎎/L)</th>\n",
       "      <th>TP(㎎/L)</th>\n",
       "      <th>유량(㎥/s)</th>\n",
       "      <th>클로로필 a(㎎/㎥)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>년/월/일</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-09-04</th>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.651</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.677</td>\n",
       "      <td>20.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-09-11</th>\n",
       "      <td>24.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>9.5</td>\n",
       "      <td>2.433</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.892</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-09-18</th>\n",
       "      <td>20.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.042</td>\n",
       "      <td>0.132</td>\n",
       "      <td>3.393</td>\n",
       "      <td>25.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-09-25</th>\n",
       "      <td>20.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.187</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.585</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-11-08</th>\n",
       "      <td>11.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>5.7</td>\n",
       "      <td>3.393</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.242</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-31</th>\n",
       "      <td>22.7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>7.7</td>\n",
       "      <td>3.598</td>\n",
       "      <td>0.043</td>\n",
       "      <td>141.215</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-08</th>\n",
       "      <td>22.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.254</td>\n",
       "      <td>0.050</td>\n",
       "      <td>287.252</td>\n",
       "      <td>18.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-13</th>\n",
       "      <td>24.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>8.6</td>\n",
       "      <td>2.843</td>\n",
       "      <td>0.044</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-21</th>\n",
       "      <td>24.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2.433</td>\n",
       "      <td>0.025</td>\n",
       "      <td>115.604</td>\n",
       "      <td>10.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-28</th>\n",
       "      <td>25.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2.249</td>\n",
       "      <td>0.054</td>\n",
       "      <td>101.127</td>\n",
       "      <td>12.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3218 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            수온(℃)  BOD(㎎/L)  COD(㎎/L)  TN(㎎/L)  TP(㎎/L)  유량(㎥/s)  클로로필 a(㎎/㎥)\n",
       "년/월/일                                                                        \n",
       "2012-09-04   24.0       2.0      11.0    2.651    0.123    0.677         20.4\n",
       "2012-09-11   24.5       1.8       9.5    2.433    0.107    0.892          7.2\n",
       "2012-09-18   20.8       2.7       9.0    2.042    0.132    3.393         25.2\n",
       "2012-09-25   20.6       1.4       5.6    2.187    0.060    0.585         12.0\n",
       "2012-11-08   11.8       1.8       5.7    3.393    0.074    0.242          9.2\n",
       "...           ...       ...       ...      ...      ...      ...          ...\n",
       "2022-05-31   22.7       2.9       7.7    3.598    0.043  141.215          5.9\n",
       "2022-06-08   22.8       3.0       8.0    3.254    0.050  287.252         18.8\n",
       "2022-06-13   24.0       2.6       8.6    2.843    0.044      NaN         17.7\n",
       "2022-06-21   24.6       1.6       8.4    2.433    0.025  115.604         10.1\n",
       "2022-06-28   25.5       2.4       8.3    2.249    0.054  101.127         12.7\n",
       "\n",
       "[3218 rows x 7 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys_seven = yongsan[features_important]\n",
    "\n",
    "ys_seven"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**입력 데이터셋 결측치 처리**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "유량 특성에 여전히 335개 결측치가 포함되어 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "수온(℃)            0\n",
       "BOD(㎎/L)         0\n",
       "COD(㎎/L)         0\n",
       "TN(㎎/L)          0\n",
       "TP(㎎/L)          0\n",
       "유량(㎥/s)        335\n",
       "클로로필 a(㎎/㎥)      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys_seven.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "335개는 전체 데이터셋의 10% 정도이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10410192666252331"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_missing_values = ys_seven.isna().sum().sum()\n",
    "num_missing_values/ys_seven.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "유량 특성에만 있는 결측치는 모두 0으로 대체한다.\n",
    "\n",
    "RNN 모델에 드롭아웃(dropout)을 적용하면 일부 특성이 어차피 0으로 지정된다.\n",
    "따라서 입력 데이터셋의 결측치가 너무 많지 않다면\n",
    "드롭아웃 효과에 의해 결측치의 영향이 묻히게 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "수온(℃)          0\n",
       "BOD(㎎/L)       0\n",
       "COD(㎎/L)       0\n",
       "TN(㎎/L)        0\n",
       "TP(㎎/L)        0\n",
       "유량(㎥/s)        0\n",
       "클로로필 a(㎎/㎥)    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys_seven = ys_seven.fillna(0)\n",
    "ys_seven.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**특성 정규화**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모든 특성을 정규화한다. \n",
    "\n",
    "먼저 특성별 평균값과 표준편차를 계산한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys_mean = ys_seven.mean(axis=0)\n",
    "ys_std = ys_seven.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "평균은 0, 표준편차는 1로 변환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>수온(℃)</th>\n",
       "      <th>BOD(㎎/L)</th>\n",
       "      <th>COD(㎎/L)</th>\n",
       "      <th>TN(㎎/L)</th>\n",
       "      <th>TP(㎎/L)</th>\n",
       "      <th>유량(㎥/s)</th>\n",
       "      <th>클로로필 a(㎎/㎥)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>년/월/일</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-09-04</th>\n",
       "      <td>0.934475</td>\n",
       "      <td>-0.841111</td>\n",
       "      <td>1.229895</td>\n",
       "      <td>-0.738148</td>\n",
       "      <td>-0.191344</td>\n",
       "      <td>-0.218735</td>\n",
       "      <td>-0.212939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-09-11</th>\n",
       "      <td>0.996661</td>\n",
       "      <td>-0.949860</td>\n",
       "      <td>0.668484</td>\n",
       "      <td>-0.859148</td>\n",
       "      <td>-0.340261</td>\n",
       "      <td>-0.218198</td>\n",
       "      <td>-0.647142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-09-18</th>\n",
       "      <td>0.536479</td>\n",
       "      <td>-0.460491</td>\n",
       "      <td>0.481346</td>\n",
       "      <td>-1.076170</td>\n",
       "      <td>-0.107578</td>\n",
       "      <td>-0.211948</td>\n",
       "      <td>-0.055047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-09-25</th>\n",
       "      <td>0.511605</td>\n",
       "      <td>-1.167357</td>\n",
       "      <td>-0.791187</td>\n",
       "      <td>-0.995688</td>\n",
       "      <td>-0.777704</td>\n",
       "      <td>-0.218965</td>\n",
       "      <td>-0.489250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-11-08</th>\n",
       "      <td>-0.582882</td>\n",
       "      <td>-0.949860</td>\n",
       "      <td>-0.753760</td>\n",
       "      <td>-0.326306</td>\n",
       "      <td>-0.647402</td>\n",
       "      <td>-0.219822</td>\n",
       "      <td>-0.581354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-31</th>\n",
       "      <td>0.772789</td>\n",
       "      <td>-0.351743</td>\n",
       "      <td>-0.005211</td>\n",
       "      <td>-0.212523</td>\n",
       "      <td>-0.935928</td>\n",
       "      <td>0.132430</td>\n",
       "      <td>-0.689904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-08</th>\n",
       "      <td>0.785226</td>\n",
       "      <td>-0.297369</td>\n",
       "      <td>0.107072</td>\n",
       "      <td>-0.403457</td>\n",
       "      <td>-0.870777</td>\n",
       "      <td>0.497334</td>\n",
       "      <td>-0.265570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-13</th>\n",
       "      <td>0.934475</td>\n",
       "      <td>-0.514866</td>\n",
       "      <td>0.331637</td>\n",
       "      <td>-0.631580</td>\n",
       "      <td>-0.926621</td>\n",
       "      <td>-0.220426</td>\n",
       "      <td>-0.301753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-21</th>\n",
       "      <td>1.009099</td>\n",
       "      <td>-1.058608</td>\n",
       "      <td>0.256782</td>\n",
       "      <td>-0.859148</td>\n",
       "      <td>-1.103460</td>\n",
       "      <td>0.068435</td>\n",
       "      <td>-0.551749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-28</th>\n",
       "      <td>1.121035</td>\n",
       "      <td>-0.623614</td>\n",
       "      <td>0.219354</td>\n",
       "      <td>-0.961276</td>\n",
       "      <td>-0.833548</td>\n",
       "      <td>0.032261</td>\n",
       "      <td>-0.466224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3218 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               수온(℃)  BOD(㎎/L)  COD(㎎/L)   TN(㎎/L)   TP(㎎/L)   유량(㎥/s)  \\\n",
       "년/월/일                                                                    \n",
       "2012-09-04  0.934475 -0.841111  1.229895 -0.738148 -0.191344 -0.218735   \n",
       "2012-09-11  0.996661 -0.949860  0.668484 -0.859148 -0.340261 -0.218198   \n",
       "2012-09-18  0.536479 -0.460491  0.481346 -1.076170 -0.107578 -0.211948   \n",
       "2012-09-25  0.511605 -1.167357 -0.791187 -0.995688 -0.777704 -0.218965   \n",
       "2012-11-08 -0.582882 -0.949860 -0.753760 -0.326306 -0.647402 -0.219822   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2022-05-31  0.772789 -0.351743 -0.005211 -0.212523 -0.935928  0.132430   \n",
       "2022-06-08  0.785226 -0.297369  0.107072 -0.403457 -0.870777  0.497334   \n",
       "2022-06-13  0.934475 -0.514866  0.331637 -0.631580 -0.926621 -0.220426   \n",
       "2022-06-21  1.009099 -1.058608  0.256782 -0.859148 -1.103460  0.068435   \n",
       "2022-06-28  1.121035 -0.623614  0.219354 -0.961276 -0.833548  0.032261   \n",
       "\n",
       "            클로로필 a(㎎/㎥)  \n",
       "년/월/일                    \n",
       "2012-09-04    -0.212939  \n",
       "2012-09-11    -0.647142  \n",
       "2012-09-18    -0.055047  \n",
       "2012-09-25    -0.489250  \n",
       "2012-11-08    -0.581354  \n",
       "...                 ...  \n",
       "2022-05-31    -0.689904  \n",
       "2022-06-08    -0.265570  \n",
       "2022-06-13    -0.301753  \n",
       "2022-06-21    -0.551749  \n",
       "2022-06-28    -0.466224  \n",
       "\n",
       "[3218 rows x 7 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys_seven = (ys_seven - ys_mean)/ys_std\n",
    "ys_seven"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시계열 데이터 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시간의 흐름을 고려해서 시계열(timeseries) 데이터로 처리한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**날짜별로 정렬**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저 날짜별로 정렬한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys_seven = ys_seven.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**훈련셋과 테스트셋 지정**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련셋, 검증셋, 테스트셋을 7:2:1의 비율로 나눈다.\n",
    "단, 테스트셋은 날짜를 기준으로 나중에 측정된 데이터를 이용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(ys_seven.shape[0] * 0.7)\n",
    "val_size = int(ys_seven.shape[0] * 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 훈련셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = ys_seven[six_features][:train_size]\n",
    "train_targets = ys_seven[target_feature][:train_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 검증셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_set = ys_seven[six_features][train_size : train_size + val_size]\n",
    "val_targets = ys_seven[target_feature][train_size : train_size + val_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 테스트셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = ys_seven[six_features][train_size + val_size:]\n",
    "test_targets = ys_seven[target_feature][train_size + val_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**시계열 데이터로 변환**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시계열 데이터 샘플을 `sequence_length` 만큼의 타임 스텝(time step)로\n",
    "구성한다.\n",
    "예측값은 미래가 아닌 현재의 클로로필-A 수치로 지정한다.\n",
    "\n",
    "- 배치 크기: 32\n",
    "- 공정한 훈련을 위해 구성된 시계열 샘플을 뒤섞는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length=50  # 타임 스텝 크기\n",
    "\n",
    "train_dataset = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    train_set,\n",
    "    targets=train_targets[sequence_length-1:],\n",
    "    sequence_length=sequence_length,\n",
    "    shuffle=True,\n",
    "    batch_size=32)\n",
    "\n",
    "val_dataset = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    val_set,\n",
    "    targets=val_targets[sequence_length-1:],\n",
    "    sequence_length=sequence_length,\n",
    "    shuffle=True,\n",
    "    batch_size=32)\n",
    "\n",
    "test_dataset = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    test_set,\n",
    "    targets=test_targets[sequence_length-1:],\n",
    "    sequence_length=sequence_length,\n",
    "    shuffle=True,\n",
    "    batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "입력 데이터셋의 배치의 모양은 `(32, 50, 6)`이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples shape: (32, 50, 6)\n",
      "targets shape: (32,)\n"
     ]
    }
   ],
   "source": [
    "for samples, targets in train_dataset:\n",
    "    print(\"samples shape:\", samples.shape)\n",
    "    print(\"targets shape:\", targets.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**케라스 활용**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Dense` 모델 사용**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "타임시리즈로 구성된 샘플을 1차원 텐서로 푼 다음에 `Dense` 모델을 적용해본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 4.1348 - mae: 0.9702 - val_loss: 1.2239 - val_mae: 0.6474\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 0.6139 - mae: 0.5589 - val_loss: 0.9480 - val_mae: 0.6598\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.3952 - mae: 0.4407 - val_loss: 1.3256 - val_mae: 0.8075\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 0.2905 - mae: 0.3814 - val_loss: 0.8903 - val_mae: 0.6489\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.2302 - mae: 0.3362 - val_loss: 0.9979 - val_mae: 0.5602\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 0.1812 - mae: 0.3046 - val_loss: 0.8568 - val_mae: 0.5155\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.1381 - mae: 0.2616 - val_loss: 0.8840 - val_mae: 0.5307\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.1363 - mae: 0.2528 - val_loss: 0.7672 - val_mae: 0.4946\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.1067 - mae: 0.2275 - val_loss: 0.7786 - val_mae: 0.4943\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0970 - mae: 0.2146 - val_loss: 0.9071 - val_mae: 0.5766\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0949 - mae: 0.2124 - val_loss: 0.8306 - val_mae: 0.5085\n",
      "Epoch 12/100\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 0.0856 - mae: 0.1974 - val_loss: 0.7362 - val_mae: 0.5099\n",
      "Epoch 13/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0645 - mae: 0.1823 - val_loss: 0.7806 - val_mae: 0.5186\n",
      "Epoch 14/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0649 - mae: 0.1762 - val_loss: 0.7760 - val_mae: 0.4972\n",
      "Epoch 15/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0683 - mae: 0.1766 - val_loss: 0.8002 - val_mae: 0.5112\n",
      "Epoch 16/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0656 - mae: 0.1698 - val_loss: 0.7843 - val_mae: 0.5015\n",
      "Epoch 17/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0599 - mae: 0.1624 - val_loss: 0.7419 - val_mae: 0.5191\n",
      "Epoch 18/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0528 - mae: 0.1549 - val_loss: 0.7553 - val_mae: 0.5217\n",
      "Epoch 19/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0473 - mae: 0.1461 - val_loss: 0.7541 - val_mae: 0.4868\n",
      "Epoch 20/100\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 0.0505 - mae: 0.1449 - val_loss: 0.7102 - val_mae: 0.4920\n",
      "Epoch 21/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0464 - mae: 0.1446 - val_loss: 0.7569 - val_mae: 0.5009\n",
      "Epoch 22/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0433 - mae: 0.1389 - val_loss: 0.7893 - val_mae: 0.4991\n",
      "Epoch 23/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0417 - mae: 0.1372 - val_loss: 0.7558 - val_mae: 0.4952\n",
      "Epoch 24/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0401 - mae: 0.1359 - val_loss: 0.7316 - val_mae: 0.4780\n",
      "Epoch 25/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0366 - mae: 0.1281 - val_loss: 0.7568 - val_mae: 0.5150\n",
      "Epoch 26/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0400 - mae: 0.1313 - val_loss: 0.7182 - val_mae: 0.4996\n",
      "Epoch 27/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0359 - mae: 0.1264 - val_loss: 0.7385 - val_mae: 0.4821\n",
      "Epoch 28/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0337 - mae: 0.1240 - val_loss: 0.7678 - val_mae: 0.5000\n",
      "Epoch 29/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0302 - mae: 0.1162 - val_loss: 0.7574 - val_mae: 0.4948\n",
      "Epoch 30/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0363 - mae: 0.1236 - val_loss: 0.7482 - val_mae: 0.4993\n",
      "Epoch 31/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0317 - mae: 0.1165 - val_loss: 0.7912 - val_mae: 0.5048\n",
      "Epoch 32/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0313 - mae: 0.1115 - val_loss: 0.7459 - val_mae: 0.4938\n",
      "Epoch 33/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0281 - mae: 0.1107 - val_loss: 0.7579 - val_mae: 0.4879\n",
      "Epoch 34/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0269 - mae: 0.1073 - val_loss: 0.7641 - val_mae: 0.5134\n",
      "Epoch 35/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0308 - mae: 0.1100 - val_loss: 0.7184 - val_mae: 0.4848\n",
      "Epoch 36/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0250 - mae: 0.1034 - val_loss: 0.7527 - val_mae: 0.5141\n",
      "Epoch 37/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0262 - mae: 0.1092 - val_loss: 0.7229 - val_mae: 0.4990\n",
      "Epoch 38/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0258 - mae: 0.1046 - val_loss: 0.7416 - val_mae: 0.4915\n",
      "Epoch 39/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0210 - mae: 0.0974 - val_loss: 0.7231 - val_mae: 0.4799\n",
      "Epoch 40/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0238 - mae: 0.1018 - val_loss: 0.7415 - val_mae: 0.4872\n",
      "Epoch 41/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0233 - mae: 0.0976 - val_loss: 0.7262 - val_mae: 0.4757\n",
      "Epoch 42/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0214 - mae: 0.0953 - val_loss: 0.7962 - val_mae: 0.4930\n",
      "Epoch 43/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0224 - mae: 0.1002 - val_loss: 0.7686 - val_mae: 0.4860\n",
      "Epoch 44/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0203 - mae: 0.0933 - val_loss: 0.7398 - val_mae: 0.4858\n",
      "Epoch 45/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0233 - mae: 0.0954 - val_loss: 0.7773 - val_mae: 0.5054\n",
      "Epoch 46/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0179 - mae: 0.0879 - val_loss: 0.7481 - val_mae: 0.4989\n",
      "Epoch 47/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0201 - mae: 0.0916 - val_loss: 0.7354 - val_mae: 0.4827\n",
      "Epoch 48/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0205 - mae: 0.0924 - val_loss: 0.7729 - val_mae: 0.4958\n",
      "Epoch 49/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0184 - mae: 0.0886 - val_loss: 0.7540 - val_mae: 0.4814\n",
      "Epoch 50/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0190 - mae: 0.0873 - val_loss: 0.7398 - val_mae: 0.4856\n",
      "Epoch 51/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0838 - val_loss: 0.7415 - val_mae: 0.4900\n",
      "Epoch 52/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0208 - mae: 0.0875 - val_loss: 0.7558 - val_mae: 0.4942\n",
      "Epoch 53/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0150 - mae: 0.0817 - val_loss: 0.7393 - val_mae: 0.4831\n",
      "Epoch 54/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0175 - mae: 0.0855 - val_loss: 0.7293 - val_mae: 0.4832\n",
      "Epoch 55/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0171 - mae: 0.0837 - val_loss: 0.7465 - val_mae: 0.4904\n",
      "Epoch 56/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0176 - mae: 0.0816 - val_loss: 0.7306 - val_mae: 0.4915\n",
      "Epoch 57/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0150 - mae: 0.0808 - val_loss: 0.7155 - val_mae: 0.4724\n",
      "Epoch 58/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0183 - mae: 0.0824 - val_loss: 0.7448 - val_mae: 0.5047\n",
      "Epoch 59/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0144 - mae: 0.0766 - val_loss: 0.7624 - val_mae: 0.4960\n",
      "Epoch 60/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0157 - mae: 0.0794 - val_loss: 0.7558 - val_mae: 0.4897\n",
      "Epoch 61/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0178 - mae: 0.0782 - val_loss: 0.7263 - val_mae: 0.4816\n",
      "Epoch 62/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0144 - mae: 0.0750 - val_loss: 0.7573 - val_mae: 0.4927\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0140 - mae: 0.0745 - val_loss: 0.7118 - val_mae: 0.4960\n",
      "Epoch 64/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0767 - val_loss: 0.7425 - val_mae: 0.4791\n",
      "Epoch 65/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0127 - mae: 0.0727 - val_loss: 0.7165 - val_mae: 0.4835\n",
      "Epoch 66/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0765 - val_loss: 0.7240 - val_mae: 0.4782\n",
      "Epoch 67/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0128 - mae: 0.0712 - val_loss: 0.7559 - val_mae: 0.4962\n",
      "Epoch 68/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0138 - mae: 0.0733 - val_loss: 0.7452 - val_mae: 0.4887\n",
      "Epoch 69/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0132 - mae: 0.0714 - val_loss: 0.7241 - val_mae: 0.4907\n",
      "Epoch 70/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0140 - mae: 0.0747 - val_loss: 0.7560 - val_mae: 0.4884\n",
      "Epoch 71/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0135 - mae: 0.0711 - val_loss: 0.7262 - val_mae: 0.4869\n",
      "Epoch 72/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0149 - mae: 0.0727 - val_loss: 0.7279 - val_mae: 0.4813\n",
      "Epoch 73/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0110 - mae: 0.0680 - val_loss: 0.7474 - val_mae: 0.4779\n",
      "Epoch 74/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0129 - mae: 0.0699 - val_loss: 0.7375 - val_mae: 0.4864\n",
      "Epoch 75/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0131 - mae: 0.0692 - val_loss: 0.7508 - val_mae: 0.4833\n",
      "Epoch 76/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0110 - mae: 0.0667 - val_loss: 0.7314 - val_mae: 0.4776\n",
      "Epoch 77/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0129 - mae: 0.0720 - val_loss: 0.7363 - val_mae: 0.4891\n",
      "Epoch 78/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0120 - mae: 0.0709 - val_loss: 0.7461 - val_mae: 0.4932\n",
      "Epoch 79/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0118 - mae: 0.0674 - val_loss: 0.7235 - val_mae: 0.4961\n",
      "Epoch 80/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0122 - mae: 0.0694 - val_loss: 0.7416 - val_mae: 0.4818\n",
      "Epoch 81/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0107 - mae: 0.0643 - val_loss: 0.7130 - val_mae: 0.4769\n",
      "Epoch 82/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0105 - mae: 0.0636 - val_loss: 0.7534 - val_mae: 0.4958\n",
      "Epoch 83/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0103 - mae: 0.0663 - val_loss: 0.7318 - val_mae: 0.4873\n",
      "Epoch 84/100\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 0.0121 - mae: 0.0662 - val_loss: 0.7098 - val_mae: 0.4710\n",
      "Epoch 85/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0111 - mae: 0.0654 - val_loss: 0.7400 - val_mae: 0.4898\n",
      "Epoch 86/100\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 0.0107 - mae: 0.0639 - val_loss: 0.7082 - val_mae: 0.4717\n",
      "Epoch 87/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0104 - mae: 0.0641 - val_loss: 0.7859 - val_mae: 0.4984\n",
      "Epoch 88/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0109 - mae: 0.0650 - val_loss: 0.7259 - val_mae: 0.4706\n",
      "Epoch 89/100\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 0.0089 - mae: 0.0597 - val_loss: 0.7243 - val_mae: 0.4796\n",
      "Epoch 90/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0098 - mae: 0.0626 - val_loss: 0.7424 - val_mae: 0.4859\n",
      "Epoch 91/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0093 - mae: 0.0608 - val_loss: 0.7420 - val_mae: 0.4818\n",
      "Epoch 92/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0098 - mae: 0.0606 - val_loss: 0.7293 - val_mae: 0.4848\n",
      "Epoch 93/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0101 - mae: 0.0629 - val_loss: 0.7465 - val_mae: 0.4764\n",
      "Epoch 94/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0098 - mae: 0.0606 - val_loss: 0.7459 - val_mae: 0.4878\n",
      "Epoch 95/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0106 - mae: 0.0604 - val_loss: 0.7330 - val_mae: 0.4863\n",
      "Epoch 96/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0595 - val_loss: 0.7559 - val_mae: 0.4872\n",
      "Epoch 97/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0106 - mae: 0.0594 - val_loss: 0.7275 - val_mae: 0.4913\n",
      "Epoch 98/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0095 - mae: 0.0588 - val_loss: 0.7566 - val_mae: 0.4850\n",
      "Epoch 99/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0093 - mae: 0.0597 - val_loss: 0.7788 - val_mae: 0.4930\n",
      "Epoch 100/100\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0096 - mae: 0.0600 - val_loss: 0.7488 - val_mae: 0.4789\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.5590 - mae: 0.5214\n",
      "Test MAE: 0.52\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(sequence_length, len(features_important)-1))\n",
    "x = layers.Flatten()(inputs)\n",
    "x = layers.Dense(1024, activation=\"relu\")(x)\n",
    "x = layers.Dense(1024, activation=\"relu\")(x)\n",
    "x = layers.Dense(1024, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(1)(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"yeongsan_dense.keras\",\n",
    "                                    save_best_only=True)\n",
    "] \n",
    "\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "history = model.fit(train_dataset,\n",
    "                    epochs=100,\n",
    "                    validation_data=val_dataset,\n",
    "                    callbacks=callbacks)\n",
    "\n",
    "model = keras.models.load_model(\"yeongsan_dense.keras\")\n",
    "print(f\"Test MAE: {model.evaluate(test_dataset)[1]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GRU 모델 사용**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 34s 433ms/step - loss: 0.8217 - mae: 0.6627 - val_loss: 1.1413 - val_mae: 0.6798\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 28s 413ms/step - loss: 0.6343 - mae: 0.5688 - val_loss: 0.7891 - val_mae: 0.5190\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 29s 419ms/step - loss: 0.4731 - mae: 0.4842 - val_loss: 0.6919 - val_mae: 0.4906\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 29s 419ms/step - loss: 0.4533 - mae: 0.4660 - val_loss: 0.6752 - val_mae: 0.4656\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 29s 420ms/step - loss: 0.4289 - mae: 0.4531 - val_loss: 0.6503 - val_mae: 0.4662\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 28s 408ms/step - loss: 0.4021 - mae: 0.4398 - val_loss: 0.6435 - val_mae: 0.4886\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 28s 408ms/step - loss: 0.3999 - mae: 0.4426 - val_loss: 0.6094 - val_mae: 0.4515\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 29s 412ms/step - loss: 0.3965 - mae: 0.4307 - val_loss: 0.6205 - val_mae: 0.4557\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 28s 407ms/step - loss: 0.3840 - mae: 0.4239 - val_loss: 0.6068 - val_mae: 0.4606\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 28s 410ms/step - loss: 0.3778 - mae: 0.4196 - val_loss: 0.6043 - val_mae: 0.4436\n",
      "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.4639 - mae: 0.4868\n",
      "Test MAE: 0.49\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(sequence_length, len(features_important)-1))\n",
    "x = layers.GRU(50, recurrent_dropout=0.5, return_sequences=True)(inputs)\n",
    "x = layers.GRU(50, recurrent_dropout=0.5, return_sequences=True)(x)\n",
    "x = layers.GRU(50, recurrent_dropout=0.5)(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1)(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "  \n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"yeongsan_gru.keras\",\n",
    "                                    save_best_only=True)\n",
    "]\n",
    "                     \n",
    "model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "history = model.fit(train_dataset,\n",
    "                    epochs=10,\n",
    "                    validation_data=val_dataset,\n",
    "                    callbacks=callbacks)\n",
    "\n",
    "model = keras.models.load_model(\"yeongsan_gru.keras\") \n",
    "\n",
    "print(f\"Test MAE: {model.evaluate(test_dataset)[1]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "69/69 [==============================] - 6s 31ms/step - loss: 0.8490 - mae: 0.6776 - val_loss: 1.2436 - val_mae: 0.7500\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.6097 - mae: 0.5468 - val_loss: 0.7129 - val_mae: 0.4851\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.4035 - mae: 0.4298 - val_loss: 0.6162 - val_mae: 0.4537\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.3787 - mae: 0.4113 - val_loss: 0.5900 - val_mae: 0.4466\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.3580 - mae: 0.3968 - val_loss: 0.5905 - val_mae: 0.4648\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.3455 - mae: 0.3881 - val_loss: 0.5881 - val_mae: 0.4569\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.3338 - mae: 0.3838 - val_loss: 0.6138 - val_mae: 0.4921\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.3240 - mae: 0.3772 - val_loss: 0.5884 - val_mae: 0.4465\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.3128 - mae: 0.3690 - val_loss: 0.5793 - val_mae: 0.4450\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.3038 - mae: 0.3642 - val_loss: 0.5900 - val_mae: 0.4480\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.2972 - mae: 0.3630 - val_loss: 0.5924 - val_mae: 0.4502\n",
      "Epoch 12/100\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.2885 - mae: 0.3593 - val_loss: 0.5937 - val_mae: 0.4393\n",
      "Epoch 13/100\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.2822 - mae: 0.3543 - val_loss: 0.6084 - val_mae: 0.4448\n",
      "Epoch 14/100\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.2725 - mae: 0.3491 - val_loss: 0.6095 - val_mae: 0.4458\n",
      "Epoch 15/100\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.2622 - mae: 0.3459 - val_loss: 0.6373 - val_mae: 0.4380\n",
      "Epoch 16/100\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.2656 - mae: 0.3442 - val_loss: 0.6085 - val_mae: 0.4495\n",
      "Epoch 17/100\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.2594 - mae: 0.3418 - val_loss: 0.6191 - val_mae: 0.4502\n",
      "Epoch 18/100\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.2513 - mae: 0.3386 - val_loss: 0.6145 - val_mae: 0.4526\n",
      "Epoch 19/100\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.2430 - mae: 0.3336 - val_loss: 0.6537 - val_mae: 0.4710\n",
      "Epoch 20/100\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.2449 - mae: 0.3324 - val_loss: 0.6333 - val_mae: 0.4577\n",
      "Epoch 21/100\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.2381 - mae: 0.3289 - val_loss: 0.6259 - val_mae: 0.4515\n",
      "Epoch 22/100\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.2350 - mae: 0.3290 - val_loss: 0.6221 - val_mae: 0.4512\n",
      "Epoch 23/100\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.2308 - mae: 0.3254 - val_loss: 0.6265 - val_mae: 0.4538\n",
      "Epoch 24/100\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.2250 - mae: 0.3215 - val_loss: 0.6318 - val_mae: 0.4445\n",
      "Epoch 25/100\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.2201 - mae: 0.3177 - val_loss: 0.6344 - val_mae: 0.4443\n",
      "9/9 [==============================] - 1s 8ms/step - loss: 0.5238 - mae: 0.4917\n",
      "Test MAE: 0.49\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(sequence_length, len(features_important)-1))\n",
    "x = layers.GRU(32, return_sequences=True)(inputs)\n",
    "x = layers.GRU(32, return_sequences=True)(x)\n",
    "x = layers.GRU(32, return_sequences=True)(x)\n",
    "x = layers.GRU(32)(x)\n",
    "# x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1)(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "  \n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_mae\", patience=10, restore_best_weights=True)\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"yeongsan_gru.keras\",\n",
    "                                    save_best_only=True),\n",
    "    early_stopping_cb\n",
    "]\n",
    "                     \n",
    "model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "history = model.fit(train_dataset,\n",
    "                    epochs=100,\n",
    "                    validation_data=val_dataset,\n",
    "                    callbacks=callbacks)\n",
    "\n",
    "model = keras.models.load_model(\"yeongsan_gru.keras\") \n",
    "\n",
    "print(f\"Test MAE: {model.evaluate(test_dataset)[1]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**모델 지정**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "33b995ba57ec8806df76ad412cbfca6e91844af7e84c0aab5f00a2382a2b11c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
